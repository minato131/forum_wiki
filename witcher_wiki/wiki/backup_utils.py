# wiki/backup_utils.py
import os
import json
import zipfile
import shutil
from django.conf import settings
from django.utils import timezone
from .models import Backup
from datetime import datetime, timedelta


def create_backup(backup_type='full', description=''):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""

    try:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ –±—ç–∫–∞–ø–µ
        timestamp = timezone.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"{backup_type}_backup_{timestamp}"

        backup = Backup.objects.create(
            name=backup_name,
            file_path='',  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
            backup_type=backup_type,
            status='in_progress',
            description=description
        )

        # –ü—É—Ç–∏ –¥–ª—è –±—ç–∫–∞–ø–æ–≤
        backup_dir = os.path.join(settings.BASE_DIR, 'backups')
        os.makedirs(backup_dir, exist_ok=True)

        backup_path = os.path.join(backup_dir, f"{backup_name}.zip")

        # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
        with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö SQLite
            db_path = settings.DATABASES['default']['NAME']
            if not os.path.isabs(db_path):
                db_path = os.path.join(settings.BASE_DIR, db_path)

            if db_path and os.path.exists(db_path) and backup_type in ['full', 'database']:
                zipf.write(db_path, 'database.sqlite3')
                print(f"‚úì –î–æ–±–∞–≤–ª–µ–Ω–∞ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {db_path}")

            # –ú–µ–¥–∏–∞—Ñ–∞–π–ª—ã
            if backup_type in ['full', 'media']:
                media_dir = settings.MEDIA_ROOT
                if os.path.exists(media_dir):
                    media_files_added = 0
                    for root, dirs, files in os.walk(media_dir):
                        for file in files:
                            try:
                                file_path = os.path.join(root, file)
                                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã (> 50MB)
                                if os.path.getsize(file_path) > 50 * 1024 * 1024:
                                    continue
                                arcname = os.path.relpath(file_path, settings.BASE_DIR)
                                zipf.write(file_path, arcname)
                                media_files_added += 1
                            except Exception as e:
                                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file}: {e}")

                    print(f"‚úì –î–æ–±–∞–≤–ª–µ–Ω–æ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤: {media_files_added}")

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                'backup_name': backup_name,
                'backup_type': backup_type,
                'created_at': timezone.now().isoformat(),
                'description': description,
                'database_engine': settings.DATABASES['default']['ENGINE'],
                'system_info': {
                    'python_version': os.sys.version,
                    'platform': os.sys.platform,
                }
            }

            zipf.writestr('metadata.json', json.dumps(metadata, indent=2, ensure_ascii=False))

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –±—ç–∫–∞–ø–∞
        backup.file_path = backup_path
        backup.file_size = os.path.getsize(backup_path)
        backup.status = 'completed'
        backup.metadata = metadata
        backup.save()

        print(f"‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_name} ({backup.file_size_display()})")

        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã (–±–æ–ª—å—à–µ 30 –¥–Ω–µ–π)
        cleanup_old_backups(backup_dir, days=30)

        return backup

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±—ç–∫–∞–ø–∞: {str(e)}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        if 'backup' in locals():
            backup.status = 'failed'
            backup.save(update_fields=['status'])
        raise e


def cleanup_old_backups(backup_dir, days=30):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
    cutoff_date = timezone.now() - timedelta(days=days)

    for filename in os.listdir(backup_dir):
        if filename.endswith('.zip'):
            file_path = os.path.join(backup_dir, filename)

            try:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞
                file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                file_time = timezone.make_aware(file_time)

                if file_time < cutoff_date:
                    os.remove(file_path)

                    # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å—å –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –µ—Å—Ç—å
                    backup_name = filename.replace('.zip', '')
                    Backup.objects.filter(name=backup_name).delete()

                    print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {filename}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {filename}: {str(e)}")


def create_date_specific_backup(date_str, backup_type='full', description=''):
    """–°–æ–∑–¥–∞–µ—Ç –±—ç–∫–∞–ø –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É"""
    from .models import Article

    try:
        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
        backup_date = datetime.strptime(date_str, '%Y-%m-%d').date()

        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ –±—ç–∫–∞–ø–µ
        timestamp = timezone.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"date_{backup_date}_{backup_type}_backup_{timestamp}"

        backup = Backup.objects.create(
            name=backup_name,
            file_path='',
            backup_type=backup_type,
            status='in_progress',
            description=f"{description} (–∑–∞ {backup_date})"
        )

        # –ü—É—Ç–∏ –¥–ª—è –±—ç–∫–∞–ø–æ–≤
        backup_dir = os.path.join(settings.BASE_DIR, 'backups')
        os.makedirs(backup_dir, exist_ok=True)

        backup_path = os.path.join(backup_dir, f"{backup_name}.zip")

        # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
        with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            # –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–∞—Ç–µ–π –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É
            articles = Article.objects.filter(created_at__date=backup_date)

            articles_data = []
            for article in articles:
                articles_data.append({
                    'id': article.id,
                    'title': article.title,
                    'slug': article.slug,
                    'content': article.content,
                    'author': article.author.username,
                    'created_at': article.created_at.isoformat(),
                    'status': article.status,
                    'categories': [cat.name for cat in article.categories.all()],
                    'tags': [tag.name for tag in article.tags.all()],
                })

            # –î–æ–±–∞–≤–ª—è–µ–º JSON —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç–∞—Ç–µ–π
            json_filename = f'articles_{backup_date}.json'
            zipf.writestr(json_filename, json.dumps(articles_data, indent=2, ensure_ascii=False))

            # –ü–æ–ª–Ω—ã–π –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            if backup_type == 'full':
                db_path = settings.DATABASES['default']['NAME']
                if not os.path.isabs(db_path):
                    db_path = os.path.join(settings.BASE_DIR, db_path)

                if os.path.exists(db_path):
                    zipf.write(db_path, 'database.sqlite3')

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                'backup_name': backup_name,
                'backup_type': backup_type,
                'backup_date': str(backup_date),
                'created_at': timezone.now().isoformat(),
                'description': description,
                'article_count': len(articles_data),
                'date_specific': True,
            }

            zipf.writestr('metadata.json', json.dumps(metadata, indent=2, ensure_ascii=False))

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –±—ç–∫–∞–ø–∞
        backup.file_path = backup_path
        backup.file_size = os.path.getsize(backup_path)
        backup.status = 'completed'
        backup.metadata = metadata
        backup.save()

        return backup

    except Exception as e:
        if 'backup' in locals():
            backup.status = 'failed'
            backup.save()
        raise e