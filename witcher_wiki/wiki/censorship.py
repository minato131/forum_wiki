# wiki/censorship.py
import re
from django import forms
from django.core.exceptions import ValidationError
from django.utils.html import escape


class CensorshipService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ü–µ–Ω–∑—É—Ä—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–Ω—ã—Ö –Ω–∞–ø–∏—Å–∞–Ω–∏–π
    BANNED_WORDS = [
        # ============== –ú–ê–¢ ==============
        # –û—Å–Ω–æ–≤–Ω–æ–π –º–∞—Ç
        '—Ö—É[–π–∏—ã—è]', '–ø[–∏—ñ]–∑–¥[–∞—É–µ–æ]', '—ë–±[–∞—É]', '–µ–±[–∞—É]',
        '–±–ª—è[–¥—Ç]—å', '–±–ª—è', '—Å[—Éy]–∫[–∞a]', '–ø–∏–¥[–æo]—Ä',
        '–≥[–∞a]–Ω–¥[–æo]–Ω', '–º[—Éy]–¥[–∞a–µe]–∫', '—Ö[—Éy][—ë–µe]',

        # –û–±—Ö–æ–¥–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è
        '—Ö[—Éy][–π–∏–π]', '—Ö[—Éy]–π', '—Ö[—Éy]—è', '—Ö[—Éy]–∏',
        '–ø[–∏i—ñ]–∑–¥', '–ø[–∏i—ñ]–∑–¥[–∞a—Éy]', '–ø[–∏i—ñ]–∑–¥[–µe–æo]',
        '—ë–±', '–µ–±[–∞a]–Ω', '–µ–±[–∞a]–ª', '–µ–±[–∞a]—Ç[—å—ä]',
        '–±–ª[—èa]–¥[—å—ä]', '–±–ª[—èa]', '–±–ª[—èa]—Ö',
        '—Å[—Éy]—á[–∞a]', '—Å[—Éy]—á–∫[–∞a]',
        '–ø[–∏i]–¥[–∞a]—Ä', '–ø[–∏i]–¥—Ä', '–ø[–∏i]–¥[–æo]—Ä[–∞a]—Å',

        # ============== –ì–†–£–ë–´–ï –°–õ–û–í–ê ==============
        '–∂[–æo]–ø[–∞a]', '–ø[–µe]–Ω[–∏i—ñ]—Å', '–≤[–∞a]–≥[–∏i]–Ω[–∞a]',
        '–¥[–µe]–±[–∏i—ñ]–ª', '–¥[–∞a]—É–Ω', '[—Éy]—Ä[–æo]–¥',
        '—Ç[—Éy]–ø[–æo][–π–∏–π]', '–≥[–æo]–≤–Ω[–æo]',

        # ============== –ê–ù–ì–õ–ò–ô–°–ö–ò–ô –ú–ê–¢ ==============
        'fuck', 'shit', 'bitch', 'asshole', 'dick', 'cock',
        'pussy', 'cunt', 'whore', 'slut',

        # ============== –û–°–ö–û–†–ë–õ–ï–ù–ò–Ø ==============
        '–¥[–µe]–±–∏–ª', '–¥[—Éy]—Ä[–∞a]–∫', '–∏–¥–∏–æ—Ç', '–∫—Ä–µ—Ç–∏–Ω',
        '–º[–æo]—Ä–¥[–∞a]', '—Ä[–æo]–∂[–∞a]', '—É—Ä–æ–¥',

        # ============== –†–ê–°–ò–°–¢–°–ö–ò–ï –í–´–†–ê–ñ–ï–ù–ò–Ø ==============
        '—á[—Éy]—Ä–∫[–∞a]', '—Ö[–∞a]—á', '—á[—Éy]—Ä[–∞a]', '–±–ª[—èa]—Ö',

        # ============== –°–ï–ö–°–£–ê–õ–¨–ù–´–ï –û–°–ö–û–†–ë–õ–ï–ù–ò–Ø ==============
        '—à–ª[—éy]—Ö[–∞a]', '–±–ª[—èa]–¥[—å—ä]', '–ø—Ä[–æo]—Å—Ç[–∏i]—Ç[—Éy]—Ç–∫[–∞a]',
        '—à–º–∞—Ä[–∞a]', '–±–ª[—èa]—à',
    ]

    # –°–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —Å—á–∏—Ç–∞–µ–º –º–∞—Ç–æ–º (–ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è)
    WHITELIST = [
        '–ø–∏—Å—å–º–æ', '–ø–∏—Å–∞–ª', '–ø–∏—Å–∞–ª–∏', '–ø–∏—Å–∞—Ç—å',
        '–æ—Ç–ø—Ä–∞–≤—å', '–æ—Ç–ø—Ä–∞–≤–ª—è–π', '–æ—Ç–ø—Ä–∞–≤–∏–ª',
        '–±–ª—è—Ç—å', '–±–ª–∏–Ω', '–±–ª–∏–Ω–æ–≤',  # –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ–¥—ã
        '—Å—É–∫', '—Å—É–∫–∞—Ç—å',  # –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –æ—Ö–æ—Ç—ã
        '—Å—Ç—Ä–∞—Ö—É–π',  # –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏—è
        '–ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö—É–π', '–ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö–æ–≤–∞–ª',
        '–ø–∏—Å—é–Ω', '–ø–∏—Å—é–Ω–æ–∫',  # –¥–µ—Ç—Å–∫–∏–µ —Å–ª–æ–≤–∞
    ]

    @classmethod
    def _prepare_pattern(cls, word):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ regex –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –¥–ª—è —Å–ª–æ–≤–∞"""
        # –ó–∞–º–µ–Ω—è–µ–º —Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã –Ω–∞ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å –ª–∞—Ç–∏–Ω–∏—Ü–µ–π
        replacements = {
            '–∞': '[–∞a@]', '–±': '[–±b6]', '–≤': '[–≤v]', '–≥': '[–≥g]',
            '–¥': '[–¥d]', '–µ': '[–µe—ë]', '—ë': '[—ë–µe]', '–∂': '[–∂zh]',
            '–∑': '[–∑z3]', '–∏': '[–∏i1]', '–π': '[–πy]', '–∫': '[–∫k]',
            '–ª': '[–ªl]', '–º': '[–ºm]', '–Ω': '[–Ωn]', '–æ': '[–æo0]',
            '–ø': '[–øp]', '—Ä': '[—Är]', '—Å': '[—Åc]', '—Ç': '[—Çt]',
            '—É': '[—Éy]', '—Ñ': '[—Ñf]', '—Ö': '[—Öx]', '—Ü': '[—Üc]',
            '—á': '[—ách]', '—à': '[—àsh]', '—â': '[—âsch]', '—ä': '[—ä]',
            '—ã': '[—ãy]', '—å': '[—å]', '—ç': '[—çe]', '—é': '[—éyu]',
            '—è': '[—èya]',
        }

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–æ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω
        pattern = word.lower()
        for cyr, variants in replacements.items():
            pattern = pattern.replace(cyr, variants)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
        pattern = r'[^\w]*'.join(list(pattern))

        # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤–∞
        return r'\b' + pattern + r'\b'

    @classmethod
    def contains_banned_words(cls, text):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (has_banned, found_words, positions)
        """
        if not text:
            return False, [], []

        text_lower = text.lower()
        found_words = []
        positions = []

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ - –µ—Å–ª–∏ —Å–ª–æ–≤–æ –≤ –±–µ–ª–æ–º —Å–ø–∏—Å–∫–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        for whitelist_word in cls.WHITELIST:
            if whitelist_word in text_lower:
                # –£–¥–∞–ª—è–µ–º —ç—Ç–æ —Å–ª–æ–≤–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                text_lower = text_lower.replace(whitelist_word, ' ' * len(whitelist_word))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ
        for banned_word in cls.BANNED_WORDS:
            pattern = re.compile(banned_word, re.IGNORECASE)
            matches = pattern.finditer(text)

            for match in matches:
                matched_word = match.group()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ —á–∞—Å—Ç—å—é –¥—Ä—É–≥–æ–≥–æ —Å–ª–æ–≤–∞
                start, end = match.start(), match.end()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤–∞
                if start > 0 and text[start - 1].isalnum():
                    continue
                if end < len(text) and text[end].isalnum():
                    continue

                found_words.append(matched_word)
                positions.append((start, end))

        return bool(found_words), found_words, positions

    @classmethod
    def filter_text(cls, text, replacement='[—Ü–µ–Ω–∑—É—Ä–∞]'):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç, –∑–∞–º–µ–Ω—è—è –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (filtered_text, found_words)
        """
        if not text:
            return text, []

        has_banned, found_words, positions = cls.contains_banned_words(text)

        if not has_banned:
            return text, []

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∑–∞–º–µ–Ω—ã
        positions_sorted = sorted(zip(positions, found_words), key=lambda x: x[0][0])

        # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ (—Å –∫–æ–Ω—Ü–∞ –∫ –Ω–∞—á–∞–ª—É, —á—Ç–æ–±—ã –ø–æ–∑–∏—Ü–∏–∏ –Ω–µ —Å–±–∏–≤–∞–ª–∏—Å—å)
        filtered_text = text
        offset = 0

        for (start, end), word in positions_sorted:
            actual_start = start + offset
            actual_end = end + offset

            # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–≤–æ
            filtered_text = filtered_text[:actual_start] + replacement + filtered_text[actual_end:]

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ –∏–∑-–∑–∞ —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã –∑–∞–º–µ–Ω—ã
            offset += len(replacement) - (end - start)

        return filtered_text, list(set(found_words))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

    @classmethod
    def get_banned_words_count(cls):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ"""
        return len(cls.BANNED_WORDS)


class CensorshipFormMixin:
    """–ú–∏–∫—Å–∏–Ω –¥–ª—è Django —Ñ–æ—Ä–º —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ü–µ–Ω–∑—É—Ä—ã"""

    def clean(self):
        cleaned_data = super().clean()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è —Ñ–æ—Ä–º—ã
        for field_name, field in self.fields.items():
            if self._is_text_field(field):
                if field_name in cleaned_data:
                    text = cleaned_data[field_name]
                    if text:
                        has_banned, found_words, _ = CensorshipService.contains_banned_words(text)

                        if has_banned:
                            self._raise_censorship_error(field_name, found_words)

        return cleaned_data

    def _is_text_field(self, field):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–ª–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–º"""
        field_types = [
            forms.CharField,
            forms.TextField,
            forms.Textarea,
            forms.TextInput,
        ]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –ø–æ–ª—è
        for field_type in field_types:
            if isinstance(field, field_type):
                return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∏–¥–∂–µ—Ç
        widget_name = field.widget.__class__.__name__
        if widget_name in ['Textarea', 'TextInput', 'CKEditor5Widget']:
            return True

        return False

    def _raise_censorship_error(self, field_name, found_words):
        """–í—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤"""
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º—ã—Ö —Å–ª–æ–≤
        display_words = found_words[:3]
        words_display = ', '.join(display_words)

        if len(found_words) > 3:
            words_display += f' –∏ –µ—â–µ {len(found_words) - 3}...'

        raise ValidationError({
            field_name: ValidationError(
                f'üö´ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞: {words_display}. '
                f'–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–¥–∞–ª–∏—Ç–µ –æ—Å–∫–æ—Ä–±–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞.',
                code='censorship_violation'
            )
        })


class CensorshipAdminMixin:
    """–ú–∏–∫—Å–∏–Ω –¥–ª—è –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ü–µ–Ω–∑—É—Ä—ã"""

    def save_model(self, request, obj, form, change):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–Ω–∑—É—Ä—É –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –∞–¥–º–∏–Ω–∫–µ"""
        text_fields = self._get_text_fields(obj)

        for field_name, field_value in text_fields:
            if field_value:
                has_banned, found_words, _ = CensorshipService.contains_banned_words(str(field_value))

                if has_banned:
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ø—ã—Ç–∫—É
                    self.message_user(
                        request,
                        f'‚ö†Ô∏è –í –ø–æ–ª–µ "{field_name}" –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞: {", ".join(found_words[:3])}',
                        level='WARNING'
                    )

                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ–∫—Å—Ç
                    filtered_text, _ = CensorshipService.filter_text(str(field_value))
                    setattr(obj, field_name, filtered_text)

        super().save_model(request, obj, form, change)

    def _get_text_fields(self, obj):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π –º–æ–¥–µ–ª–∏"""
        text_fields = []

        for field in obj._meta.get_fields():
            if hasattr(field, 'get_internal_type'):
                field_type = field.get_internal_type()
                if field_type in ['CharField', 'TextField']:
                    field_name = field.name
                    if hasattr(obj, field_name):
                        field_value = getattr(obj, field_name)
                        if field_value:
                            text_fields.append((field_name, field_value))

        return text_fields


# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è—Ö
def censor_text(text):
    """–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ü–µ–Ω–∑—É—Ä—ã —Ç–µ–∫—Å—Ç–∞"""
    return CensorshipService.filter_text(text)[0]


def check_text_for_banned_words(text):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞"""
    return CensorshipService.contains_banned_words(text)